{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO 6205 – Program Structure and Algorithms\n",
    "\n",
    "# Assignment 5\n",
    "\n",
    "Student Name: Christ Rodrigues\n",
    "\n",
    "Professor: Nik Bear Brown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1 (5 Points)**\n",
    "\n",
    "In a candy store, there are n different types of candies, and each time you purchase a candy, you randomly and uniformly receive one of the available types. Assuming all candies are equally likely to be chosen, how many candies must you buy before you expect to have at least one of each type?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "Let's denote the number of candies needed to collect at least one of each type as X. We can approach this problem using the concept of the expected value.\n",
    "\n",
    "For the first candy, you have no choice but to pick a new type. For the second candy, there is a (n-1)/n chance of picking a new type (since you've already obtained one type). For the third candy, there is a (n-2)/n chance of picking a new type, and so on.\n",
    "\n",
    "The expected value E(X) can be calculated as follows:\n",
    "\n",
    "$E(X)=1+ \\frac{n}{n-1} + \\frac{n}{n-2} +. . . + \\frac{n}{2} + \\frac{n}{1}$\n",
    "\n",
    "​\n",
    "We can rewrite this expression as:\n",
    "\n",
    "$E(X)= n(\\frac{1}{n} + \\frac{1}{n-1} + \\frac{1}{n-2} + . . . + \\frac{1}{2} + \\frac{1}{1})$\n",
    "\n",
    "\n",
    "This sum is known as the harmonic series, and it is approximately equal to the natural logarithm of n. Therefore:\n",
    "\n",
    "$E(X)=n⋅ln(n)$\n",
    "\n",
    "So, the expected number of candies you need to buy to collect at least one of each type is $n⋅ln(n)$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2 (10 Points) Short answer:**\n",
    "\n",
    "consider a 2-D game called \"BoxMaze.\" In BoxMaze, the player needs to navigate a maze filled with unit-square boxes to reach a specific goal position. The rules are as follows:\n",
    "\n",
    "a. Initially, the planar square grid is filled with some unit-square boxes and the player placed in one cell of the grid.\n",
    "\n",
    "b. The player can move to any adjacent free square (without a box).\n",
    "\n",
    "c. The player can push any adjacent box, and that box slides in that direction to the maximal extent possible, i.e., until the box is against another box or a wall.\n",
    "\n",
    "d. The goal is to get the player to a particular position.\n",
    "\n",
    "A solution to BoxMaze is specified as a list of the following moves and x, y coordinates:\n",
    "\n",
    "MovePlayer(x, y) # moves the player from its current position to the position x, y\n",
    "PushBox(x, y) # pushes a box from its current position to the position x, y\n",
    "CheckGoal(player) # takes the position of the player and checks whether it is at the goal\n",
    "\n",
    "Is the BoxMaze problem in NP? If so prove it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "**1. NP Membership (2 points):**\n",
    "The BoxMaze problem unequivocally resides within NP, signifying that any conjectured solution can be rigorously and efficiently verified in polynomial time.\n",
    "\n",
    "**2. Polynomial-Time Certificate (2 points):**\n",
    "A judiciously designed polynomial-time certificate for the solution encompasses the meticulously crafted sequence of moves and box pushes. The validation process entails a meticulous simulation of these moves on the initial configuration.\n",
    "\n",
    "**3. Running-Time Analysis (1 point):**\n",
    "The running time, a critical metric in algorithmic efficiency, demonstrates polynomial characteristics. This is perceptible through the meticulous traversal of the list of moves, where m moves encapsulate the algorithm's temporal complexity. The constant time complexity of comparing x and y positions on the grid further contributes to the algorithm's efficiency.\n",
    "\n",
    "**4. Polynomial-Time Certificate (2 points):**\n",
    "- **Iterative Verification (Loop through the list with m moves):**\n",
    "  - Each move undergoes a meticulous examination for potential rule infractions. If any such violations are detected, the verification process promptly returns a verdict of \"no.\"\n",
    "  - The completion of the moves list without encountering rule violations, coupled with the player attaining the goal position, elicits a conclusive \"yes\" from the verification process.\n",
    "\n",
    "**5. Polynomial-Time Certificate Details:**\n",
    "- **MovePlayer(x, y):**\n",
    "  - Constant-time verification assesses the player's capability to traverse to an adjacent free square. The confirmation of adjacency requires a meticulous check ensuring that either x or y is precisely one unit away from x' or y'. Subsequently, an efficient query ascertains the presence of an entity at x', y' in constant time.\n",
    "\n",
    "- **PushBox(x, y):**\n",
    "  - The rigorous validation of player adjacency and their ability to effect a push operation transpires within constant time.\n",
    "  - The push operation, incrementing or decrementing either x or y, invokes constant-time checks to discern the existence of entities at each point along the proposed path.\n",
    "\n",
    "- **CheckGoal(player):**\n",
    "  - The final verification step ensures, in constant time, that the player occupies the goal coordinates at x and y.\n",
    "\n",
    "**6. Analysis of Running Time (2 points):**\n",
    "The algorithm's temporal behavior manifests as a worst-case scenario characterized by m * (the average length of a push). However, in its optimal guise, the algorithm operates within the time complexity bounds of O(m), a testament to the efficiency derived from each move's inherent constant time operations.\n",
    "\n",
    "**7. Reflective Synthesis And Example(1 point):**\n",
    "In culmination, the BoxMaze problem's inclusion in NP is substantiated through a judiciously constructed polynomial-time certificate and a profound understanding of the algorithm's temporal intricacies. This reflective synthesis underscores the robustness of the solution in addressing the complexities inherent in maze navigation.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Imagine a BoxMaze represented as a 5x5 grid, where 'P' denotes the player, 'B' represents a box, 'G' signifies the goal, and '.' indicates an empty space.\n",
    "\n",
    "\n",
    "Grid Configuration:\n",
    "-------------\n",
    "| . | . | . | . | . |\n",
    "-------------\n",
    "| . | P | . | . | . |\n",
    "-------------\n",
    "| . | . | . | B | . |\n",
    "-------------\n",
    "| . | . | B | G | . |\n",
    "-------------\n",
    "| . | . | . | . | . |\n",
    "-------------\n",
    "\n",
    "\n",
    "In this scenario, the player 'P' needs to navigate the maze and reach the goal 'G'. The grid is filled with boxes 'B' that can be pushed to clear a path. A valid solution sequence could be:\n",
    "\n",
    "MovePlayer(1, 2)\n",
    "PushBox(2, 3)\n",
    "MovePlayer(3, 2)\n",
    "PushBox(3, 1)\n",
    "MovePlayer(4, 2)\n",
    "MovePlayer(4, 3)\n",
    "CheckGoal([4, 4])\n",
    "In this example, the solution sequence comprises moving the player and pushing boxes strategically to reach the goal. The sequence demonstrates adherence to the rules of the BoxMaze problem. The verification process would confirm the validity of each move and the final position of the player, affirming the successful solution to the BoxMaze.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3 (5 Points) Nash Equilibria Analysis:**\n",
    "\n",
    "Consider the given payoff matrix for a two-player symmetric game with actions \"A\" and \"B\":\n",
    "\n",
    "\\[\n",
    "\\begin{array}{cc|cc}\n",
    " & & \\text{A} & \\text{B} \\\\\n",
    "\\hline\n",
    "\\text{A} & & 3,2 & 2,1 \\\\\n",
    "\\text{B} & & 1,2 & 2,3 \\\\\n",
    "\\end{array}\n",
    "\\]\n",
    "\n",
    "**Does the payoff matrix have any Nash equilibria? Provide reasoning for your answer.**\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "To determine Nash equilibria, we evaluate each potential action profile:\n",
    "\n",
    "1. **(A, A):**\n",
    "   - Player 2 can unilaterally increase its payoff from 1 to 2 by choosing \"B\" instead of \"A.\" Therefore, (A, A) is not a Nash equilibrium.\n",
    "\n",
    "2. **(A, B):**\n",
    "   - Player 1 can unilaterally increase its payoff from 2 to 3 by choosing \"B\" instead of \"A.\" Therefore, (A, B) is not a Nash equilibrium.\n",
    "\n",
    "3. **(B, A):**\n",
    "   - Player 1 can unilaterally increase its payoff from 1 to 2 by choosing \"A\" instead of \"B.\" Therefore, (B, A) is not a Nash equilibrium.\n",
    "\n",
    "4. **(B, B):**\n",
    "   - Player 2 can unilaterally increase its payoff from 1 to 2 by choosing \"A\" instead of \"B.\" Therefore, (B, B) is not a Nash equilibrium.\n",
    "\n",
    "\n",
    "\n",
    "In each potential action profile, at least one player has an incentive to deviate from the given strategy unilaterally. This deviation results in an increased payoff for the deviating player, indicating the absence of Nash equilibrium.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Let's consider the action profile (A, A). In this case, Player 2 can deviate by choosing \"B\" to increase their payoff from 1 to 2. This exemplifies the lack of mutual best responses, essential for a Nash equilibrium.\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "After thorough examination, we conclude that the game described by the given payoff matrix has no Nash equilibrium. The absence of mutual best responses in any action profile implies that no stable solution exists where players' strategies are optimal given the opponent's strategy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4 (5 Points) What defines stability in a Cellular Automaton configuration?**\n",
    "\n",
    "**Solution:**\n",
    "A configuration in a Cellular Automaton is considered stable if all cells are satisfied.\n",
    "\n",
    "*Additional Definitions:*\n",
    "- **Definition 1:** With respect to a configuration S, a transition between cells i and j is considered \"good\" if \\(w_{ij} \\cdot S_i \\cdot S_j < 0\\). Specifically, if \\(w_{ij} < 0\\), then \\(S_i = S_j\\); if \\(w_{ij} > 0\\), \\(S_i \\neq S_j\\).\n",
    "\n",
    "- **Definition 2:** A cell i is deemed satisfied in a configuration S if the summation of weights over all incident good transitions is greater than or equal to the summation of weights over incident bad transitions. Mathematically, if \\(\\sum_{\\text{good transitions}} w_{ij} \\geq \\sum_{\\text{bad transitions}} w_{ij}\\).\n",
    "\n",
    "**Example:**\n",
    "Consider a Cellular Automaton with a 1-dimensional array of cells represented as `[-1, 1, -1, 1]`. The weights between adjacent cells are `[2, -3, 1]`. To check stability:\n",
    "\n",
    "1. **Transition Checks:**\n",
    "   - Transition 1 (between cells 1 and 2): \\(2 \\cdot (-1) \\cdot 1 = -2 < 0\\) (good)\n",
    "   - Transition 2 (between cells 2 and 3): \\((-3) \\cdot 1 \\cdot (-1) = 3 > 0\\) (bad)\n",
    "   - Transition 3 (between cells 3 and 4): \\(1 \\cdot (-1) \\cdot 1 = -1 < 0\\) (good)\n",
    "\n",
    "2. **Node Satisfaction Checks:**\n",
    "   - Cell 1: \\(\\text{Weight of good transitions} = 2 + 1 = 3\\), \\(\\text{Weight of bad transitions} = 0\\). Satisfied.\n",
    "   - Cell 2: \\(\\text{Weight of good transitions} = -2 + 1 = -1\\), \\(\\text{Weight of bad transitions} = -3\\). Satisfied.\n",
    "   - Cell 3: \\(\\text{Weight of good transitions} = -1\\), \\(\\text{Weight of bad transitions} = 3\\). Not satisfied.\n",
    "   - Cell 4: \\(\\text{Weight of good transitions} = 0\\), \\(\\text{Weight of bad transitions} = -1\\). Satisfied.\n",
    "\n",
    "Since not all cells are satisfied in this example, the configuration is not stable.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5 (5 Points) Provide an argument or proof for the questions below:**\n",
    "\n",
    "**(A 2 points) Can you always convert a randomized algorithm into a deterministic algorithm?**\n",
    "\n",
    "**(B 3 points) Can you always convert a deterministic algorithm into a randomized algorithm?**\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "**(A 2 points) Can you always convert a randomized algorithm into a deterministic algorithm?**\n",
    "\n",
    "Yes, a randomized algorithm can be converted into a deterministic algorithm by repeating the randomized process multiple times and taking a majority vote. Given that the randomized algorithm is likely to produce the correct answer, multiple runs increase the probability of correctness. Therefore, it is possible to convert a randomized algorithm into a deterministic one by introducing repetitions. This ensures a deterministic output while potentially sacrificing efficiency. \n",
    "\n",
    "*Example:*\n",
    "Consider a randomized algorithm that, with a certain probability, outputs the correct answer to a problem. To convert it into a deterministic algorithm, run the algorithm multiple times (e.g., k times) and take the majority vote as the final answer. Mathematically:\n",
    "\n",
    "$Final Output = Majority (Run_1, Run_2, . . .Run_k)$ \n",
    "   \n",
    "\n",
    "**(B 3 points) Can you always convert a deterministic algorithm into a randomized algorithm?**\n",
    "\n",
    "No, it is not always possible to convert a deterministic algorithm into a randomized algorithm. Deterministic algorithms have a fixed, predictable behavior for any given input, making them inherently different from randomized algorithms that introduce randomness into their processes. Consider an example of sorting a list of numbers in ascending order using a deterministic algorithm. Introducing randomness to this process may not yield meaningful results or improve the algorithm's performance. Therefore, it is not always feasible to convert a deterministic algorithm into a randomized one. \n",
    "\n",
    "*Example:*\n",
    "Take a deterministic sorting algorithm like merge sort. Introducing randomness to its steps, such as randomizing the choice of pivot in quicksort, may not enhance its performance or provide any benefit, making the conversion impractical.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6 (5 Points) Probability of Rolling a Number on a Fair Die:**\n",
    "\n",
    "A fair six-sided die is rolled, and the probability of rolling a specific number $k$ is $p_k$, where $1 \\leq k \\leq 6$. What is the expected number of independent rolls $X$ until the first occurrence of the specified number?\n",
    "\n",
    "For instance, with a fair die where $p_k = \\frac{1}{6}$ for all $k$, we expect to roll the specified number in $1/p_k$ or 6 rolls.\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "The expectation of the number of rolls until the first occurrence of a specified number can be expressed as a function of the respective probabilities $p_k$:\n",
    "\n",
    "$$ E(X) = \\frac{1}{p_k} $$\n",
    "\n",
    "*Example:*\n",
    "Consider a loaded die where $p_k = \\frac{1}{3}$ for a specific number $k$. The expected number of rolls until the first occurrence of this number would be:\n",
    "\n",
    "$$ E(X) = \\frac{1}{\\frac{1}{3}} = 3 $$\n",
    "\n",
    "**Extension to General Case:**\n",
    "\n",
    "For a fair die, where $p_k = \\frac{1}{6}$ for all $k$, the expectation can be expressed as:\n",
    "\n",
    "$$ E(X) = \\frac{1}{p_k} = \\frac{1}{\\frac{1}{6}} = 6 $$\n",
    "\n",
    "This formula generalizes the expectation of independent rolls until the first occurrence of a specified number for a given probability distribution on the die.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7 (5 Points):**\n",
    "\n",
    "Consider a modified algorithm for computing the greatest common divisor (GCD) of two numbers based on a different approach. The algorithm is defined as follows:\n",
    "\n",
    "```python\n",
    "def modified_gcd_algorithm(m, n):\n",
    "    if(m == 0):\n",
    "        return n\n",
    "    elif(m % 2 == 0):\n",
    "        return modified_gcd_algorithm(m // 2, n)\n",
    "    elif(n % 2 == 0):\n",
    "        return modified_gcd_algorithm(m, n // 2)\n",
    "    else:\n",
    "        return modified_gcd_algorithm(abs(m - n), min(m, n))\n",
    "```\n",
    "\n",
    "**(A 3 points) Write a recurrence relation for the modified GCD algorithm.**\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "$ T(n) = T(n/2) + c $\n",
    "\n",
    "*Note: Any recurrence relation of the form $ T(n) = T(n/b) + c $ where $ b $ is some estimate $b > 1 $ is acceptable. So $ T(n) = T(n/2) + c $ OR $ T(n) = T(n/b) + c $ OR $ T(n) \\leq T(n/2) + O(1) $ is given full credit.*\n",
    "\n",
    "*Note as to why $ n/2 $: For any two integers $ m $ and $ n $ such that $ n \\geq m $, it is always true that $ n \\mod m < n/2 $.*\n",
    "\n",
    "**(B 2 points) Give an expression for the runtime $ T(n) $ if your modified GCD algorithm recurrence can be solved with the Master Theorem.**\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "$ \\Theta(\\log n) $\n",
    "\n",
    "The modified GCD Algorithm $ T(n) \\leq T(n/2) + O(1) $.\n",
    "\n",
    "We can express it in the form $ T(n) = aT(n/b) + f(n) $ where $ a \\geq 1 $ and $ b > 1 $.\n",
    "\n",
    "Here, $ A = 1, b = 2, f(n) = c $.\n",
    "\n",
    "There are three cases:\n",
    "\n",
    "1. If $ f(n) = \\Theta(n^c) $ where $ c < \\log_b a $, then $ T(n) = \\Theta(n^{\\log_b a}) $.\n",
    "\n",
    "2. If $ f(n) = \\Theta(n^{\\log_b a}) $ where $ c = \\log_b a $, then $ T(n) = \\Theta(n^{\\log_b a} \\log^{p+1} n) $.\n",
    "\n",
    "3. If $ f(n) = \\Theta(n^c) $ where $ c > \\log_b a $, then $ T(n) = \\Theta(f(n)) $.\n",
    "\n",
    "In our case, $\\log_2 1 = 0 $ and $ c = n^0 \\cdot c $, so this is case B (they are equal).\n",
    "\n",
    "Therefore, $ T(n) = \\Theta(\\log n) $.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8 (10 Points) Randomized Algorithm for Maximum Matching:**\n",
    "\n",
    "Consider a random algorithm to find a maximum matching in a bipartite graph $ G = (V, E) $ with two disjoint sets of nodes, $ V_1 $ and $ V_2 $, where each node has a label indicating its availability (0 or 1), and edges connect pairs of nodes. Nodes are considered available if their labels differ. We aim to find a large matching using a randomized algorithm.\n",
    "\n",
    "Each node $ P_i $ independently selects a random value $ x_i $. It sets $ x_i $ to 1 with probability $ p = 0.7 $ and sets $ x_i $ to 0 with probability $ 1 - p = 0.3 $. It then decides to be part of the matching if and only if it chooses the value 1, and its adjacent nodes (neighbors in $ V_1 $ or $ V_2 $) choose the value 0.\n",
    "\n",
    "**(A 5 points) Give a formula for the expected size of the matching when $ p $ is set to 0.7.**\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "Assume that using the described protocol, we get a matching $ M $ that is not conflict-free. Then there must be two nodes $ P_i $ and $ P_j $ in the matching $ M $ such that both picked the value 1, and they share an edge in the graph. However, this contradicts the way our protocol was implemented, since we selected nodes that picked the value 1 and whose adjacent nodes picked the value 0. Thus, if $ P_i $ and $ P_j $ both picked the value 1, neither of them would be selected, and so the resulting matching $ M $ is conflict-free.\n",
    "\n",
    "For each node $ P_i $, the probability that it is selected depends on the fact that $ P_i $ picks the value 1 and all its adjacent nodes pick the value 0. Thus,\n",
    "\n",
    "$$ P[P_i \\text{ selected}] = p \\cdot (1 - p)^d $$\n",
    "\n",
    "where $ d $ is the degree of node $ P_i $.\n",
    "\n",
    "Since there are $ n $ nodes that pick values independently, the expected size of the matching $ M $ is:\n",
    "\n",
    "$ \\text{Expected Size of } M = \\sum_{i=1}^{n} P[P_i \\text{ selected}] $\n",
    "\n",
    "Using linearity of expectation, we can simplify this to:\n",
    "\n",
    "$ \\text{Expected Size of } M = n \\cdot P[P_i \\text{ selected}] $\n",
    "\n",
    "$ = n \\cdot p \\cdot (1 - p)^d $\n",
    "\n",
    "**(B 5 points) Provide an example with a small bipartite graph and calculate the expected size of the matching using the given formula when $ p = 0.7 $.**\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "Let's consider a bipartite graph with three nodes in $ V_1 $ (labeled $ A, B, C $) and three nodes in $ V_2 $ (labeled $ X, Y, Z $), with edges connecting $ A-X, B-Y, C-Z $. The degrees of all nodes are 1.\n",
    "\n",
    "For this example, the expected size of the matching is:\n",
    "\n",
    "$ \\text{Expected Size of } M = 6 \\cdot 0.7 \\cdot (1 - 0.7)^1 $\n",
    "\n",
    "$ = 6 \\cdot 0.7 \\cdot 0.3 $\n",
    "\n",
    "$ = 1.26 $\n",
    "\n",
    "So, the expected size of the matching is 1.26.\n",
    "\n",
    "```python\n",
    "import random\n",
    "\n",
    "def randomized_matching_probability(p, degree):\n",
    "    return p * (1 - p) ** degree\n",
    "\n",
    "def expected_matching_size(num_nodes, p, degrees):\n",
    "    return num_nodes * randomized_matching_probability(p, degrees)\n",
    "\n",
    "# Example bipartite graph with nodes labeled A, B, C, X, Y, Z\n",
    "# Edges: A-X, B-Y, C-Z\n",
    "degrees = {'A': 1, 'B': 1, 'C': 1, 'X': 1, 'Y': 1, 'Z': 1}\n",
    "\n",
    "# Probability of selecting a node in the matching\n",
    "p = 0.7\n",
    "\n",
    "# Calculate the expected size of the matching\n",
    "expected_size = expected_matching_size(len(degrees), p, degrees.values())\n",
    "\n",
    "print(f\"Expected Size of Matching: {expected_size}\")\n",
    "```\n",
    "\n",
    "This code calculates and prints the expected size of the matching for the given example bipartite graph.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9 (10 Points) Hopfield Neural Network State-Flipping Algorithm:**\n",
    "\n",
    "Consider a weighted undirected network graph with nodes labeled A-F and weights assigned to edges. We will apply the Hopfield Neural Network State-Flipping Algorithm to find a stable configuration.\n",
    "\n",
    "\n",
    "\n",
    "|   | A | B | C | D | E | F |\n",
    "|---|---|---|---|---|---|---|\n",
    "| A | - | 5 | 5 | - | - | - |\n",
    "| B | 5 | - | 9 | 3 | 1 | 4 |\n",
    "| C | 5 | 9 | - | 6 | -1| -4|\n",
    "| D | - | 3 | 6 | - | - | 2 |\n",
    "| E | - | 1 | -1| - | - | - |\n",
    "| F | - | 4 | -4| 2 | - | - |\n",
    "\n",
    "This table represents the weighted connections between nodes. The numbers in each cell indicate the weight of the edge between the corresponding nodes.\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "The Hopfield Neural Network State-Flipping Algorithm is as follows:\n",
    "\n",
    "```python\n",
    "def hopfield_flip(graph, weights):\n",
    "    S = {node: 1 for node in graph}  # Arbitrary initial configuration\n",
    "\n",
    "    def is_stable():\n",
    "        for node in graph:\n",
    "            incident_edges = graph[node]\n",
    "            good_edges_weight = sum(weights[node, neighbor] for neighbor in incident_edges if S[node] * S[neighbor] < 0)\n",
    "            bad_edges_weight = sum(weights[node, neighbor] for neighbor in incident_edges if S[node] * S[neighbor] > 0)\n",
    "            if good_edges_weight < bad_edges_weight:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    while not is_stable():\n",
    "        unsatisfied_node = next(node for node in graph if not is_satisfied(node, S, weights))\n",
    "        S[unsatisfied_node] = -S[unsatisfied_node]\n",
    "\n",
    "    return S\n",
    "\n",
    "def is_satisfied(node, S, weights):\n",
    "    incident_edges = graph[node]\n",
    "    good_edges_weight = sum(weights[node, neighbor] for neighbor in incident_edges if S[node] * S[neighbor] < 0)\n",
    "    bad_edges_weight = sum(weights[node, neighbor] for neighbor in incident_edges if S[node] * S[neighbor] > 0)\n",
    "    return good_edges_weight >= bad_edges_weight\n",
    "\n",
    "# Weighted undirected graph represented as an adjacency list\n",
    "graph = {\n",
    "    'A': ['B', 'C'],\n",
    "    'B': ['A', 'C', 'D', 'E', 'F'],\n",
    "    'C': ['A', 'B', 'D', 'E', 'F'],\n",
    "    'D': ['B', 'C', 'F'],\n",
    "    'E': ['B', 'C', 'F'],\n",
    "    'F': ['B', 'C', 'D', 'E']\n",
    "}\n",
    "\n",
    "# Edge weights\n",
    "weights = {\n",
    "    ('A', 'B'): 5,\n",
    "    ('A', 'C'): 5,\n",
    "    ('B', 'C'): 9,\n",
    "    ('B', 'D'): 3,\n",
    "    ('B', 'E'): 1,\n",
    "    ('B', 'F'): 4,\n",
    "    ('C', 'D'): 6,\n",
    "    ('C', 'E'): -1,\n",
    "    ('C', 'F'): -4,\n",
    "    ('D', 'F'): 2,\n",
    "    ('E', 'F'): -4\n",
    "}\n",
    "\n",
    "# Apply the Hopfield Neural Network State-Flipping Algorithm\n",
    "final_configuration = hopfield_flip(graph, weights)\n",
    "\n",
    "print(\"Final Stable Configuration:\")\n",
    "print(final_configuration)\n",
    "```\n",
    "\n",
    "In this code, we define the `hopfield_flip` function that implements the Hopfield Neural Network State-Flipping Algorithm. The graph is represented as an adjacency list, and edge weights are provided. The algorithm is applied, and the final stable configuration is printed. The function `is_satisfied` checks if a node is satisfied in a given configuration.\n",
    "\n",
    "The final stable configuration is reached when all nodes are satisfied, and no further flips are needed.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Q10 (10 points): Stock Trading Price Updates**\n",
    "\n",
    "Consider StockBeat, a financial news platform exploring a system to monitor stock trading prices. The platform tracks n stocks, each with a distinct positive real-numbered trading price $ p_i $. Updates on stock prices arrive in a uniformly random order, and the platform maintains a variable $ p^* $, initially set to 0, representing the highest trading price observed so far.\n",
    "\n",
    " **Objective:**\n",
    "Determine the expected number of times that $ p^* $ is updated during this process.\n",
    "\n",
    "\n",
    "**Example:**\n",
    "Suppose stock prices are \\( p_1 = $50 \\), \\( p_2 = $65 \\), and \\( p_3 = $40 \\). If the updates arrive in the order 2, 1, 3, then \\( p^* \\) is updated for 2 (since \\( p_0 \\) is initially $0) and 1, but not for 3.\n",
    "\n",
    " **Solution:**\n",
    "\n",
    "Let $ X $ be a random variable representing the number of times $ p^* $ is updated. We decompose $ X $ into indicator variables $ X_1, X_2, \\ldots, X_n $, where $ X_i = 1 $ if the $ i $-th update causes $ p^* $ to be updated, and $ X_i = 0 $ otherwise.\n",
    "\n",
    "The probability that the $ i $-th update causes $ p^* $ to be updated is $ \\frac{1}{i} $.\n",
    "\n",
    "$$ E[X_i] = \\frac{1}{i} $$\n",
    "\n",
    "By the linearity of expectation, the expected number of times $ p^* $ is updated is given by the sum of the expected values of individual indicators.\n",
    "\n",
    "$$ E[X] = \\sum E[X_i] = \\sum \\frac{1}{i} $$\n",
    "\n",
    "While this series does not have a closed-form solution, it converges. Therefore, the expected number of times that $ p^* $ is updated is approximately $ \\ln(n) $.\n",
    "\n",
    "**Code Illustration (Python):**\n",
    "\n",
    "```python\n",
    "import math\n",
    "\n",
    "def expected_updates(n):\n",
    "    return sum(1/i for i in range(1, n+1))\n",
    "\n",
    "# Example usage\n",
    "number_of_stocks = 10\n",
    "result = expected_updates(number_of_stocks)\n",
    "print(f\"Expected number of updates: {result:.4f}\")\n",
    "```\n",
    "**Reflection:**\n",
    "Understanding the distribution of the expected number of updates provides insights into the efficiency of monitoring stock prices. The approach of using indicator variables and leveraging the linearity of expectation facilitates a systematic analysis of the random process. The logarithmic relationship with the number of stocks demonstrates a characteristic of the update process, contributing to informed decision-making for the StockBeat platform.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11 (5 Points) What is the probability of getting exactly one tail after flipping four coins?**\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "When flipping four coins, there are $2^4 = 16$ possible outcomes. We need to find the number of outcomes where exactly one tail appears.\n",
    "\n",
    "Possible outcomes with exactly one tail: THHH, HTHH, HHTH, HHHT (4 outcomes)\n",
    "\n",
    "Therefore, the probability $ P(\\text{exactly one tail}) $ is given by:\n",
    "\n",
    "$ P(\\text{exactly one tail}) = \\frac{\\text{Number of favorable outcomes}}{\\text{Total number of outcomes}} = \\frac{4}{16} = \\frac{1}{4} $\n",
    "\n",
    "**Code Illustration (Python):**\n",
    "\n",
    "```python\n",
    "def probability_one_tail(num_flips):\n",
    "    total_outcomes = 2 ** num_flips\n",
    "    favorable_outcomes = 4  # THHH, HTHH, HHTH, HHHT\n",
    "    probability = favorable_outcomes / total_outcomes\n",
    "    return probability\n",
    "\n",
    "# Example usage\n",
    "num_flips = 4\n",
    "result = probability_one_tail(num_flips)\n",
    "print(f\"Probability of exactly one tail: {result}\")\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "This probability problem involves counting favorable outcomes and dividing by the total number of possible outcomes. The code snippet provides a straightforward way to calculate and display the probability in a Python environment.\n",
    "\n",
    "**Reflection:**\n",
    "\n",
    "Understanding probability is fundamental in various domains. This question and solution illustrate the concept of calculating probabilities for specific events in a simple coin-flipping scenario. The Python code demonstrates how to translate the probability formula into a computational solution, enhancing understanding and practical application.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Q12 (10 Points): Estimating Machine Learning Model Accuracy with Chernoff-Bound**\n",
    "\n",
    "**Problem Statement:**\n",
    "Suppose you are deploying a machine learning model in a production environment, and you need to estimate the accuracy of the model on a large dataset. You decide to use a sampling approach to randomly select a subset of data points and calculate the accuracy based on this sample. Use a Chernoff-bound to calculate your confidence in the approximate accuracy estimate. Choose your confidence level (e.g., 90%, 95%, or 99%), the distribution of the data points, and your sample size.\n",
    "\n",
    "**Chernoff-Bound Equation:**\n",
    "\n",
    "$$ P\\left(\\left|\\frac{1}{n}\\sum_{i=1}^{n}X_i - \\mu\\right| \\geq \\epsilon\\right) \\leq 2e^{-2n\\epsilon^2} $$\n",
    "\n",
    "Where:\n",
    "- $ X_i $ is the indicator variable for the correct classification of the $ i $-th sampled data point (1 if correct, 0 if incorrect).\n",
    "- $ \\mu $ is the true accuracy of the machine learning model.\n",
    "- $ \\epsilon $ is the margin of error.\n",
    "- $ n $ is the sample size.\n",
    "\n",
    "**Explanation:**\n",
    "1. The term $ \\frac{1}{n}\\sum_{i=1}^{n}X_i $ represents the sample mean of the indicator variables, which is essentially the observed accuracy in the sample.\n",
    "\n",
    "2. $ \\mu $ is the true accuracy of the machine learning model, and the expression $ \\left|\\frac{1}{n}\\sum_{i=1}^{n}X_i - \\mu\\right| $ calculates the absolute difference between the sample mean and the true accuracy.\n",
    "\n",
    "3. $ \\epsilon $ is the margin of error, indicating the acceptable range of deviation from the true accuracy.\n",
    "\n",
    "4. The term $ e^{-2n\\epsilon^2} $ is the exponential term that provides an upper bound on the probability of the observed accuracy deviating from the true accuracy by more than $ \\epsilon $.\n",
    "\n",
    "5. The factor of 2 in front ensures that the bound holds for both sides of the deviation.\n",
    "\n",
    "**Python Code Implementation:**\n",
    "\n",
    "```python\n",
    "import math\n",
    "\n",
    "def chernoff_bound(sample_accuracy, true_accuracy, sample_size, confidence_level):\n",
    "    epsilon = math.sqrt((1 / (2 * sample_size)) * math.log(2 / confidence_level))\n",
    "    deviation = abs(sample_accuracy - true_accuracy)\n",
    "    \n",
    "    return deviation <= epsilon\n",
    "\n",
    "# Example usage\n",
    "sample_accuracy = 0.92  # Replace with your sampled accuracy\n",
    "true_accuracy = 0.95   # Replace with your true accuracy\n",
    "sample_size = 1000     # Replace with your sample size\n",
    "confidence_level = 0.95  # Choose your confidence level (e.g., 90%, 95%, or 99%)\n",
    "\n",
    "result = chernoff_bound(sample_accuracy, true_accuracy, sample_size, confidence_level)\n",
    "print(f\"Is the estimate within the Chernoff-bound? {result}\")\n",
    "```\n",
    "\n",
    "**Reflection:**\n",
    "The Chernoff-bound provides a statistical guarantee on the reliability of our accuracy estimate based on a sample, considering the trade-off between sample size, confidence level, and the acceptable margin of error.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13 (10 Points): Resource Allocation in Cloud Environment**\n",
    "\n",
    "**Problem Statement:**\n",
    "\n",
    "In a cloud environment, there are $ m $ virtual machines (VMs) and $ n $ physical servers ($ m > n $). The resource allocation algorithm randomly selects a server to deploy each VM, all equally likely.\n",
    "\n",
    "**Chernoff-Bound Equation:**\n",
    "\n",
    "$$ P\\left(\\left|\\frac{1}{n}\\sum_{i=1}^{n}X_i - \\mu\\right| \\geq \\epsilon\\right) \\leq 2e^{-2n\\epsilon^2} $$\n",
    "\n",
    "Where:\n",
    "- $ X_i $ is the indicator variable for the deployment of a VM on the $ i $-th server (1 if selected, 0 if not selected).\n",
    "- $ \\mu $ is the expected number of VMs on each server.\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "A. **Expected Number of VMs on Each Server:**\n",
    "$$ \\text{Expected VMs on each server} = \\frac{m}{n} $$\n",
    "\n",
    "B. **Difference in Server Load:**\n",
    "$$ P(\\text{a server gets a VM}) = \\frac{1}{n} $$\n",
    "$$ P(\\text{a server gets all VMs}) = \\left(\\frac{1}{n}\\right)^m $$\n",
    "\n",
    "C. **Likelihood that a Server is \\( k \\) Times an Average Server:**\n",
    "$$ \\text{Average server load is } \\frac{m}{n} = \\mu $$\n",
    "$$ \\Pr[X > k\\mu] < e^{\\frac{k-1}{k}(k)} \\frac{m}{n} $$\n",
    "\n",
    "D. **Likelihood that a Server is \\( \\frac{1}{k} \\) Below an Average Server:**\n",
    "$$ \\text{Average server load is } \\frac{m}{n} = \\mu $$\n",
    "$$ \\Pr[X < \\frac{\\mu}{k}] < e^{-(1-\\frac{1}{k})^2} \\frac{m}{2n} $$\n",
    "\n",
    "**Example Code:**\n",
    "\n",
    "```python\n",
    "import math\n",
    "\n",
    "# Constants\n",
    "m = 120  # Total VMs\n",
    "n = 15   # Number of servers\n",
    "mu = m/n  # Expected VMs on each server\n",
    "\n",
    "# Chernoff-Bound\n",
    "epsilon = 0.08\n",
    "bound = 2 * math.exp(-2 * n * epsilon**2)\n",
    "\n",
    "# Output\n",
    "print(f\"A. Expected VMs on Each Server: {mu}\")\n",
    "print(f\"B. Difference in Server Load Bound: {bound}\")\n",
    "print(\"C. Likelihood that a Server is k Times an Average Server:\")\n",
    "print(f\"   Pr[X > k*mu] < {math.exp((k-1)/k*k) * m/n} (for a specific k)\")\n",
    "print(\"D. Likelihood that a Server is 1/k Below an Average Server:\")\n",
    "print(f\"   Pr[X < mu/k] < {math.exp(-(1-1/k)**2) * m/(2*n)} (for a specific k)\")\n",
    "```\n",
    "\n",
    "**Reflection:**\n",
    "This scenario applies the Chernoff-Bound to resource allocation in a cloud environment. The expected VMs per server, load differences, and likelihood of extreme load scenarios provide insights into the system's behavior. Adjusting parameters like \\( \\epsilon \\) allows for confidence level customization, aiding in resource management decisions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14 (5 Points): Task Assignment in a Co-op Project**\n",
    "\n",
    "**Problem Statement:**\n",
    "\n",
    "In a co-op project, you develop an algorithm for task assignment in a collaborative environment. Suppose that in a typical minute, you receive $ k $ (e.g., a bazillion) task requests, and each needs to be assigned to one of your $ n $ team members. Your algorithm randomly assigns each task to a random team member.\n",
    "\n",
    "**Reasoning:**\n",
    "\n",
    "A. **Expected Number of Tasks per Team Member:**\n",
    "   - The expected number of tasks per team member is $ \\frac{k}{n} $. This is a straightforward calculation based on the assumption of uniform task distribution.\n",
    "\n",
    "B. **Probability of High Load:**\n",
    "   - We use the Chernoff-Bound to calculate the probability of a team member receiving twice the average load. The bound provides insights into the tail behavior of the distribution and helps manage extreme cases.\n",
    "\n",
    "C. **Probability of No Load:**\n",
    "   - The probability of a team member receiving no load is $ P(X = 0) = \\left(1 - \\frac{1}{n}\\right)^k $. This is derived from the assumption that each team member has an equal chance of not getting a task.\n",
    "\n",
    "**Example Code:**\n",
    "\n",
    "```python\n",
    "import math\n",
    "\n",
    "# Constants\n",
    "k = 100  # Total tasks\n",
    "n = 10   # Number of team members\n",
    "mu = k/n  # Expected tasks per team member\n",
    "\n",
    "# Chernoff-Bound for High Load\n",
    "bound_high_load = math.exp(-mu/3)\n",
    "\n",
    "# Probability of No Load\n",
    "prob_no_load = (1 - 1/n)**k\n",
    "\n",
    "# Output\n",
    "print(f\"A. Expected Tasks per Team Member: {mu}\")\n",
    "print(f\"B. Probability of High Load: P(X > 2*mu) < {bound_high_load}\")\n",
    "print(f\"C. Probability of No Load: P(X = 0) = {prob_no_load}\")\n",
    "```\n",
    "\n",
    "**Reflection:**\n",
    "\n",
    "This scenario represents a common challenge in collaborative environments: efficient task distribution. Understanding the expected workload, extreme load probabilities, and scenarios of no load is crucial for designing algorithms that ensure fair and effective task assignment. The use of Chernoff-Bound highlights the importance of considering tail behaviors for system robustness.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15 (5 Points): Merge Sort Exploration**\n",
    "\n",
    "**Problem Statement:**\n",
    "\n",
    "**(A) Sort the list of strings below using Merge Sort. Show your work.**\n",
    "- (\"apple\", \"orange\", \"banana\", \"grape\", \"kiwi\", \"melon\", \"peach\")\n",
    "- **Solution:**\n",
    "  1. Split the list into individual elements:\n",
    "     - (\"apple\", \"orange\", \"banana\", \"grape\", \"kiwi\", \"melon\", \"peach\")\n",
    "     - (\"apple\") | (\"orange\") | (\"banana\") | (\"grape\") | (\"kiwi\") | (\"melon\") | (\"peach\")\n",
    "  2. Merge pairs of elements:\n",
    "     - (\"apple\", \"orange\") | (\"banana\", \"grape\") | (\"kiwi\", \"melon\") | (\"peach\")\n",
    "  3. Merge larger sublists:\n",
    "     - (\"apple\", \"banana\", \"grape\", \"orange\") | (\"kiwi\", \"melon\", \"peach\")\n",
    "  4. Final merge:\n",
    "     - (\"apple\", \"banana\", \"grape\", \"kiwi\", \"melon\", \"orange\", \"peach\")\n",
    "\n",
    "**(B) Write a worst case and average case recurrence relation for Merge Sort.**\n",
    "- **Worst Case Recurrence:**\n",
    "  $ T(n) = 2T\\left(\\frac{n}{2}\\right) + \\Theta(n) $\n",
    "- **Average Case Recurrence:**\n",
    "  $ T(n) = 2T\\left(\\frac{n}{2}\\right) + \\Theta(n) $\n",
    "\n",
    "**(C) Give an expression for the runtime \\(T(n)\\) if your worst case and average case Merge Sort recurrence relations can be solved with the Master Theorem.**\n",
    "- **Master Theorem:**\n",
    "  $ T(n) = aT\\left(\\frac{n}{b}\\right) + f(n) $\n",
    "  $ T(n) = 2T\\left(\\frac{n}{2}\\right) + \\Theta(n) $\n",
    "  - $ a = 2 $, $ b = 2 $, $ f(n) = n $\n",
    "  - Since $ f(n) = \\Theta(n^{\\log_b a}) $, the runtime is $ \\Theta(n \\log n) $.\n",
    "\n",
    "**Reflection:**\n",
    "\n",
    "This problem explores the application of Merge Sort, a popular sorting algorithm, to strings. Understanding the recurrence relations and runtime analysis using the Master Theorem provides insights into the efficiency of Merge Sort in different scenarios."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
