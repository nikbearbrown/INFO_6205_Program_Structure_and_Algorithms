{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2243934e-1ba2-474a-99c6-3a099b1e6cad",
   "metadata": {},
   "source": [
    "#### Question: Give brief definitions for the following:\n",
    "    i. Cut Capacity\n",
    "    ii. Residual Network\n",
    "    iii. Ford-Fulkerson Method\n",
    "    iv. Preflow-Push Algorithm\n",
    "    v. Edmonds-Karp Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf1ed86-679b-4c72-9d8e-cb2d1c227e09",
   "metadata": {},
   "source": [
    "Solution:\n",
    "1. Cut Capacity\n",
    "In the context of network flow, the cut capacity refers to the total weight or capacity of all edges crossing a cut in the network. Specifically, a cut is a division of the network's vertices into two disjoint subsets, with the source in one subset and the sink in the other. The cut capacity is critical in flow problems because it represents the maximum flow that can pass from the source to the sink — the smaller the cut capacity, the more it limits the flow through the network.\n",
    "\n",
    "2. Residual Network\n",
    "A residual network is derived from an original flow network; it represents the network's capacity to accommodate additional flow. This is achieved by adjusting the original network's edges based on the current flow. The residual network is composed of the original edges minus the flow that is already passing through them (indicating remaining capacity) and backward edges indicating the amount of flow that can be potentially redirected or reversed.\n",
    "\n",
    "3. Ford-Fulkerson Method\n",
    "The Ford-Fulkerson method is a greedy algorithm that computes the maximum flow in a flow network. The idea is to increase the flow in the network as much as possible by repeatedly finding \"augmenting paths\" (paths from the source to the sink in the residual network) and then adding this path's flow to the total flow, respecting the capacity constraints of the original network. The process is repeated until no more augmenting paths can be found in the residual network.\n",
    "\n",
    "4. Preflow-Push Algorithm\n",
    "Also known as the push-relabel algorithm, the preflow-push algorithm is used to find the maximum flow in a flow network. Unlike the Ford-Fulkerson method, which focuses on augmenting paths, the preflow-push algorithm works by first initializing a \"preflow\" and then repeatedly performing \"push\" and \"relabel\" operations to move flow around the network until the flow is maximized. A \"push\" operation sends flow from a vertex to one of its neighbors, and a \"relabel\" operation modifies the \"height\" of a vertex to allow more flow to leave it.\n",
    "\n",
    "5. Edmonds-Karp Algorithm\n",
    "The Edmonds-Karp algorithm is an implementation of the Ford-Fulkerson method for computing the maximum flow in a flow network. The main distinction of Edmonds-Karp is that it uses breadth-first search (BFS) to find the shortest augmenting path in the residual network in each iteration. The use of BFS ensures that the path found is the shortest in terms of the number of edges, which leads to a performance guarantee, or an upper bound, on the number of iterations the algorithm performs. This makes the Edmonds-Karp algorithm more efficient in practice compared to the original Ford-Fulkerson method when dealing with certain types of graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245cb93b-14f3-4246-b7ed-9de3d721b4d6",
   "metadata": {},
   "source": [
    "#### Question: Use the Bellman-Ford algorithm to find the shortest path from node A to F in the weighted directed graph. Show your work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad0f7cf-f8d4-4ae7-a31c-e58c389c4088",
   "metadata": {},
   "source": [
    "![Example Image](Q2.png)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a735dbd-5550-4abb-96ab-1f8ce31758f9",
   "metadata": {},
   "source": [
    "Solution\n",
    "pseudo code:\n",
    "function BellmanFord(graph, source):\n",
    "    distance = [∞,...,∞]\n",
    "    distance[source] = 0\n",
    "    predecessor = [null,...,null]\n",
    "\n",
    "    for i from 1 to |V|-1:\n",
    "        for each edge (u, v) in graph.edges:\n",
    "            if distance[u] + weight(u, v) < distance[v]:\n",
    "                distance[v] = distance[u] + weight(u, v)\n",
    "                predecessor[v] = u\n",
    "\n",
    "    for each edge (u, v) in graph.edges:\n",
    "        if distance[u] + weight(u, v) < distance[v]:\n",
    "            print \"Graph contains a negative-weight cycle\"\n",
    "            return\n",
    "\n",
    "    return distance, predecessor\n",
    "\n",
    "function reconstructPath(predecessor, source, target):\n",
    "    path = []\n",
    "    while target != source:\n",
    "        path.prepend(target)\n",
    "        target = predecessor[target]\n",
    "    path.prepend(source)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae7f9c9-5775-46bd-93d1-9d5637a516a8",
   "metadata": {},
   "source": [
    "Bellman-Ford Algorithm Explanation:\n",
    "\n",
    "Step 1: Initialization\n",
    "Start by initializing the distance to all vertices as infinite (∞), except for the source vertex which will be initialized to zero (0).\n",
    "Distance to A: 0 (because A is the source vertex)\n",
    "Distance to B: ∞\n",
    "Distance to C: ∞\n",
    "Distance to D: ∞\n",
    "Distance to E: ∞\n",
    "\n",
    "Step 2: Relaxation\n",
    "The main idea is to relax all the edges, and this process is repeated for |V|-1 times, where |V| is the number of vertices in the graph. During each iteration:\n",
    "\n",
    "For each edge (u, v), if the distance to vertex u plus the weight of the edge (u, v) is less than the distance to vertex v, update the distance to vertex v and set its predecessor as vertex u.\n",
    "\n",
    "After the 1st iteration:\n",
    "A -> C: The distance is updated to 2 because 0 (distance to A) + 2 (weight of A -> C) < ∞ (initial distance to C)\n",
    "Using similar logic, distance to vertices B, D, and E are also updated.\n",
    "After the 2nd iteration, distances may be updated further based on the relaxation condition.\n",
    "The above process ensures that the shortest path to any vertex v is finalized after at most |V|-1 steps.\n",
    "\n",
    "Step 3: Check for Negative Weight Cycles\n",
    "Once we've updated distances |V|-1 times, the algorithm checks for negative weight cycles. For every edge (u, v), if the distance to vertex u plus the weight of the edge (u, v) is less than the distance to vertex v, then the graph contains a negative weight cycle.\n",
    "There are no negative weight cycles as evident from the given edge weights.\n",
    "\n",
    "Results:\n",
    "Using the above steps, the algorithm will determine that the shortest path from A to D is through the path A -> C -> D with a total distance of 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6315f77-7a82-4439-bdeb-e4efbd9e5c03",
   "metadata": {},
   "source": [
    "#### Question: Use the e Ford-Fulkerson algorithm to find the shortest path from node A to F in the weighted directed graph. Show your work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216e7eff-9a63-434f-802f-c67b5f2afc6a",
   "metadata": {},
   "source": [
    "![Example Image](Q3.png)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5bf9d9d6-4523-4d14-8bb9-eff6761bd796",
   "metadata": {},
   "source": [
    "Solution:\n",
    "pseudo code:\n",
    "function fordFulkerson(graph, source, sink):\n",
    "    max_flow = 0\n",
    "    residual_graph = create a copy of the input graph (initially)\n",
    "    while there is a path from source to sink in residual_graph using BFS:\n",
    "        path_flow = find the bottleneck value of the path (minimum capacity along the path)\n",
    "        update the residual_graph by reducing capacities along the path by path_flow and increasing the reverse edges by path_flow\n",
    "        max_flow += path_flow\n",
    "    return max_flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414929c8-eb8c-438b-9f82-70e4840799a3",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "Step 1: Initialize the residual graph to be the same as the original graph.\n",
    "\n",
    "Step 2: While there exists an augmenting path from source A to sink D in the residual graph:\n",
    "\n",
    "Find the bottleneck value for the augmenting path. This is the smallest capacity along the path.\n",
    "\n",
    "Subtract the bottleneck value from all forward edges in the path and add the bottleneck value to all reverse edges.\n",
    "\n",
    "Repeat until no more augmenting paths can be found.\n",
    "\n",
    "Step 3: The maximum flow is the sum of flows on the outgoing edges from the source.\n",
    "\n",
    "Iteration 1:\n",
    "Augmenting path: A -> C -> D\n",
    "\n",
    "Bottleneck value: min(2, 5) = 2\n",
    "\n",
    "Update the residual graph:\n",
    "\n",
    "Decrease the capacity of edge A->C to 0\n",
    "Add the reverse edge C->A with capacity 2\n",
    "Decrease the capacity of edge C->D to 3\n",
    "Add the reverse edge D->C with capacity 2\n",
    "Iteration 2:\n",
    "Augmenting path: A -> B -> E -> D\n",
    "\n",
    "Bottleneck value: min(4, 4, 1) = 1\n",
    "\n",
    "Update the residual graph:\n",
    "\n",
    "Decrease the capacity of edge A->B to 3\n",
    "Add the reverse edge B->A with capacity 1\n",
    "Decrease the capacity of edge B->E to 3\n",
    "Add the reverse edge E->B with capacity 1\n",
    "Decrease the capacity of edge E->D to 0\n",
    "Add the reverse edge D->E with capacity 1\n",
    "Iteration 3:\n",
    "Augmenting path: A -> C -> B -> E -> D\n",
    "\n",
    "Bottleneck value: min(0, 4, 3, 1) = 0 (This path doesn't work because of the A->C edge)\n",
    "\n",
    "We have to find another path.\n",
    "\n",
    "Iteration 4:\n",
    "Augmenting path: A -> B -> C -> D\n",
    "\n",
    "Bottleneck value: min(3, 1, 3) = 1\n",
    "\n",
    "Update the residual graph:\n",
    "\n",
    "Decrease the capacity of edge A->B to 2\n",
    "Add the reverse edge B->A with capacity 2\n",
    "Decrease the capacity of edge B->C to 0\n",
    "Add the reverse edge C->B with capacity 1\n",
    "Decrease the capacity of edge C->D to 2\n",
    "Add the reverse edge D->C with capacity 3\n",
    "No more augmenting paths exist from A to D.\n",
    "\n",
    "Conclusion: The maximum flow from node A to node D is 2 + 1 + 1 = 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf6a2c1-805e-4d8e-aaa4-e3d1d9bf5d59",
   "metadata": {},
   "source": [
    "#### Question: Use the Preflow-Push (Push–relabel) maximum flow algorithm to find the maximum flow from node A to E in the weighted directed graph above. Show your work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be11ff8c-8403-41b1-a629-02444988038b",
   "metadata": {},
   "source": [
    "![Example Image](Q3.png)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebe73d74-38f3-4503-9b44-895b9a2d47e3",
   "metadata": {},
   "source": [
    "function preflowPush(graph, source, sink):\n",
    "    initialize preflow and heights for all nodes\n",
    "    height[source] = number of nodes in the graph\n",
    "    preflow[source] = infinity\n",
    "    for each edge (source, v):\n",
    "        flow[source, v] = capacity[source, v]\n",
    "        preflow[v] += capacity[source, v]\n",
    "        flow[v, source] = -capacity[source, v]\n",
    "\n",
    "    while there exists an overflowing node u other than source and sink:\n",
    "        if there exists an adjacent node v to u such that height[u] > height[v]:\n",
    "            push(u, v)\n",
    "        else:\n",
    "            relabel(u)\n",
    "\n",
    "    return preflow[sink]\n",
    "\n",
    "function push(u, v):\n",
    "    send = min(preflow[u], capacity[u, v] - flow[u, v])\n",
    "    flow[u, v] += send\n",
    "    flow[v, u] -= send\n",
    "    preflow[u] -= send\n",
    "    preflow[v] += send\n",
    "\n",
    "function relabel(u):\n",
    "    height[u] = 1 + min(height[v] for each edge (u, v) with positive residual capacity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3e61ab-edff-4360-a499-17dbe6c0adae",
   "metadata": {},
   "source": [
    "Steps\n",
    "Initialization:\n",
    "\n",
    "Initialize the preflow of each node to 0, except the source which is infinity.\n",
    "Initialize the height of each node to 0, except the source which is the number of nodes.\n",
    "Send as much flow as possible from the source to its neighbors.\n",
    "Main Loop:\n",
    "\n",
    "While there's an overflowing vertex u:\n",
    "Push: If there's an adjacent vertex v with a lower height and there's residual capacity between u and v, then push flow from u to v.\n",
    "Relabel: If we can't push flow from u, then increase its height.\n",
    "Let's solve:\n",
    "\n",
    "Initialization:\n",
    "\n",
    "Preflow: A=∞, B=0, C=0, D=0, E=0\n",
    "Heights: A=5, B=0, C=0, D=0, E=0\n",
    "Push as much flow from A:\n",
    "\n",
    "A->B: 4, A->C: 2. So, preflows are A=∞-6=∞, B=4, C=2.\n",
    "Iteration 1:\n",
    "\n",
    "u = C (as it's overflowing)\n",
    "Push from C->D: 2 (Bottleneck)\n",
    "Preflow: A=∞, B=4, C=0, D=2, E=0\n",
    "Iteration 2:\n",
    "\n",
    "u = B (as it's overflowing)\n",
    "Push from B->E: 1 (Bottleneck)\n",
    "Preflow: A=∞, B=3, C=0, D=2, E=1\n",
    "Iteration 3:\n",
    "\n",
    "u = E (as it's overflowing)\n",
    "Can't push, so Relabel E. New height of E = 1 + minimum height of neighbors with positive residual = 2 (considering D).\n",
    "Push from E->D: 1\n",
    "Preflow: A=∞, B=3, C=0, D=3, E=0\n",
    "Iteration 4:\n",
    "\n",
    "u = B\n",
    "Can't push, so Relabel B. New height of B = 1 + minimum height of neighbors with positive residual = 2 (considering E and C).\n",
    "Push from B->C: 1\n",
    "Preflow: A=∞, B=2, C=1, D=3, E=0\n",
    "Iteration 5:\n",
    "\n",
    "u = C\n",
    "Push from C->D: 1\n",
    "Preflow: A=∞, B=2, C=0, D=4, E=0\n",
    "No more overflowing vertices except source.\n",
    "\n",
    "Conclusion: The maximum flow from node A to node D is 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd71bf17-63e5-4a35-b1d3-979b98dee5d4",
   "metadata": {},
   "source": [
    "#### Question\n",
    "Consider a flow network with edges of varying capacities. That is, a directed graph G=(V,E) with a source vertex s∈V, a target/sink vertex t∈V, and every edge e∈E has a capacity csube. The capacities are all positive integers. Given an integer parameter l≤∣E∣, your objective is to minimize the maximum flow of the network from s to t by reducing the capacity of l edges by one unit each. You need to determine which \n",
    "l edges to decrement to achieve the smallest possible maximum flow.\n",
    "\n",
    "Provide a polynomial-time algorithm to determine the edges and ensure the maximum flow in the resultant graph G′=(V,E) is minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce42734-9b6f-4069-b6ab-2db93c29ef9a",
   "metadata": {},
   "source": [
    "Solution:\n",
    "If the minimum s-t cut in the original graph has a total capacity of C, and C≤l, we can reduce the flow to 0 by reducing the capacity of the edges in the cut by one unit each until we've used up l units. \n",
    "\n",
    "If not, let's say f>l be the value of the minimum s-t flow. We identify the minimum s-t cut (A,B), and decrement the capacity of up to l edges going out of A. The resulting sub-graph has a maximum flow value of at most f−l.\n",
    "\n",
    "However, we claim that for any set of edges F of size l, the sub-graph G′=(V,E−F) has an s-t flow value of at least f−l. This is because any cut (A,B) in G′ has at least f edges going out of A in the original graph G, and since we're only reducing the capacity by l units, there will still be at least f−l units of flow going out of A in G′. Thus, the minimum cut in G ′has a value of at least f−l, and so there exists a flow of at least this value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87efc794-de05-442b-ba74-267822f74622",
   "metadata": {},
   "source": [
    "#### Question\n",
    "Imagine a large music festival happening in a city. There are m music enthusiasts distributed across the city who wish to attend the festival. The city has l entry gates where attendees can enter. However, due to logistical constraints, each music enthusiast can only access specific gates based on their current location.\n",
    "\n",
    "Moreover, to prevent overcrowding, the festival organizers want to ensure that the attendees are evenly distributed among the entry gates. Each gate should have at most [m/l] attendees.\n",
    "\n",
    "Provide a polynomial-time algorithm to determine whether it's possible to distribute the attendees in the desired manner given their current locations and accessible gates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3ff256-8a9f-4ede-b55b-ade22d26aa66",
   "metadata": {},
   "source": [
    "Solution:\n",
    "\n",
    "1. Graph Construction:\n",
    "- Create a source node s.\n",
    "- Create a sink node t.\n",
    "- For each of the m music enthusiasts, create a node E_i.\n",
    "- For each of the l entry gates, create a node G_j.\n",
    "- Connect the source node s to each of the E_i nodes with an edge of capacity 1.\n",
    "- Connect each E_i node to the G_j nodes that they can access. These edges also have a capacity of 1.\n",
    "- Connect each G_j node to the sink node t with an edge of capacity [m/l].\n",
    "2. Algorithm:\n",
    "- Construct the bipartite graph as described above.\n",
    "- Use a max-flow algorithm, such as the Ford-Fulkerson algorithm, to find the maximum flow in this graph.\n",
    "We claim that distributing the attendees evenly among the entry gates is feasible if and only if there is an s-t flow of value m. If there's a feasible way to distribute the attendees, then we send one unit of flow from s to t along each of the paths s, E_i, G_j, t, where attendee i enters through gate j. This flow respects the capacity constraints, especially on the edges (E_i, G_j), ensuring no gate is overcrowded.\n",
    "\n",
    "Conversely, if there's a flow of value m, then it can be integral. We assign attendee i to gate j if the edge (E_i, G_j) carries one unit of flow.\n",
    "\n",
    "The time complexity mainly depends on the max-flow algorithm applied to a graph with O(m + l) nodes and O(ml) edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bd23b7-279e-498e-9023-aa1c0ca689e3",
   "metadata": {},
   "source": [
    "#### Question\n",
    "You are an expansion manager for the renowned coffee chain, \"Bean There, Done That,\" and are responsible for strategizing the brand's growth along Liberty Boulevard. The boulevard is N blocks long, with each block having precisely one potential spot for a new café. Each location i on a block has a projected revenue of ri > 0, determined by various factors like foot traffic, visibility, and competition.\n",
    "\n",
    "Your CEO is indifferent about the total number of new cafes; however, due to a non-compete clause in the franchise agreement, no two cafes can operate within adjacent blocks to prevent market saturation.\n",
    "\n",
    "Your mission is to select a subset of these N potential spots to establish new cafes in a way that the cumulative revenue from these locations is maximized, bearing in mind the restriction against opening cafes on neighboring blocks."
   ]
  },
  {
   "cell_type": "raw",
   "id": "1be56516-e3c7-4320-989e-2e1139814858",
   "metadata": {},
   "source": [
    "1. Define the Sub Problems:\n",
    "    \n",
    "Let's define dp[i] as the maximum profit that can be obtained from the first i locations (1 <= i <= N), considering the non-adjacency constraint. The sub-problem here is to find the maximum profit for each prefix of locations of length i.\n",
    "\n",
    "2. Present Your Recurrence:\n",
    "To compute dp[i], we have two choices: to include location i or not. If we include location i, we cannot include location i-1, but we take the profit ri. If we don't include location i, the answer is the same as dp[i-1]. Therefore, our recurrence relation is:\n",
    "\n",
    "dp[i] = max(dp[i-2] + ri, dp[i-1])\n",
    "\n",
    "This equation states that the maximum profit from the first i locations is either the maximum profit from the first i-2 locations plus the revenue from location i (if we decide to include it) or the maximum profit from the first i-1 locations (if we decide not to include the ith loc\n",
    "o.3.\n",
    "\n",
    "1.3 Prove your recurrence is correct:\n",
    "To prove that this recurrence is correct, we need to show that it correctly considers all possibilities ateach step.\n",
    "\n",
    "If we include the ith location (earning a revenue of ri), we cannot include the (i-1)th location due to the adjacency constraint. Thus, the best profit we can achieve in this case is dp[i-2] + ri.\n",
    "If we do not include the ith location, the adjacency constraint does not affect us, and the best profit we can achieve is the same as if we had only considered the first (i-1) locations, which is dp[i-1].\n",
    "Since these are the only two options (to include or not include the ith location), and the recurrence takes the best of these two, i4.4.orrect.\n",
    "\n",
    "P.4 State and \n",
    "rove Base Cases:\n",
    "Base Case 1: dp[0] = 0. If there are no locations, no revenue can be generated.\n",
    "Base Case 2: dp[1] = r1. If there is only one location, the maximum revenue is the revenue rom that location.\n",
    "\n",
    "Proof of Base Cases:\n",
    "Base Case 1 is trivial because no locations mean no possible profit, hence dp[0] = 0.\n",
    "For Base Case 2, since there's only one location, the adjacency constraint doesn't apply, and the only revenue you can generate is from that location itelf, hence dp[1] = r1.\n",
    "\n",
    "With these defined base cases and the recurrence relation, we can compute the answer for any N by building up the solutions to these sub-problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70174544-7ef1-4593-8fd0-7fbe31e0d51e",
   "metadata": {},
   "source": [
    "#### Question: For each of the following recurrences, give an expression for the runtime T(n) if the recurrence can be solved with the Master Theorem. Otherwise, indicate that the Master Theorem does not apply.\n",
    "    i. T(n) = 3T(n/2) + n^2\n",
    "    ii. T(n) = 2T(n/3) + n^3\n",
    "    iii. T(n) = 3T(n/4) + n\n",
    "    iv. T(n) = 2nT(n/3) + n^2.5\n",
    "    v. T(n) = n^2T(n/2) + n^3.5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d187417f-4bcb-4884-9c6f-788918cb1d5e",
   "metadata": {},
   "source": [
    "Solution: \n",
    "\n",
    "i. T(n) = 3T(n/2) + n^2\n",
    "a = 4, b = 2, and f(n) = n^2\n",
    "Here, a = b^c, where c = 2. So, it falls into Case 2 of the Master Theorem.\n",
    "T(n) = Θ(n^c * log n) = Θ(n^2 * log n)\n",
    "\n",
    "ii. T(n) = 2T(n/3) + n^3\n",
    "a = 5, b = 3, and f(n) = n^3\n",
    "Here, a > b^c, where c = 3. So, it falls into Case 1 of the Master Theorem.\n",
    "T(n) = Θ(n^c) = Θ(n^3)\n",
    "\n",
    "iii. T(n) = 3T(n/4) + n\n",
    "a = 2, b = 4, and f(n) = n\n",
    "Here, a < b^c for any positive c. So, it falls into Case 1 of the Master Theorem.\n",
    "T(n) = Θ(n^c) = Θ(1)\n",
    "\n",
    "iv. T(n) = 2nT(n/3) + n^2.5\n",
    "Master Theorem does not apply A is a function of n.\n",
    "\n",
    "v. T(n) = n^2T(n/2) + n^3.5\n",
    "Master Theorem does not apply A is a function of n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800a41c4-7ded-497b-9348-9cffe4418ace",
   "metadata": {},
   "source": [
    "#### Question \n",
    "You have a knapsack with a capacity of W, and you have 6 items with their respective weights and values as follows:\n",
    "\n",
    "- Item 1: Weight 2, Value 3\n",
    "- Item 2: Weight 3, Value 4\n",
    "- Item 3: Weight 1, Value 2\n",
    "- Item 4: Weight 4, Value 10\n",
    "- Item 5: Weight 5, Value 11\n",
    "- Item 6: Weight 2, Value 3\n",
    "\n",
    "Your task is to choose which items to put into the knapsack, such that the total weight does not exceed the knapsack's capacity W, and the total value of the items is maximized.\n",
    "What items should you choose to maximize the total value, and what is the maximum total value you can achieve?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "31420ea7-ff3e-490f-853d-bf1d2602cb74",
   "metadata": {},
   "source": [
    "Solution:\n",
    "Pseudocode: \n",
    "Initialize a 2D array dp[n+1][W+1] with zeros\n",
    "for i from 1 to n:\n",
    "    for j from 1 to W:\n",
    "        if weights[i-1] > j:\n",
    "            dp[i][j] = dp[i-1][j]\n",
    "        else:\n",
    "            dp[i][j] = max(dp[i-1][j], dp[i-1][j-weights[i-1]] + values[i-1])\n",
    "\n",
    "Initialize an empty list selected_items\n",
    "i = n\n",
    "j = W\n",
    "while i > 0 and j > 0:\n",
    "    if dp[i][j] != dp[i-1][j]:\n",
    "        Add i to selected_items\n",
    "        j = j - weights[i-1]\n",
    "    Decrement i by 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9185b675-2d5c-4252-ba19-d191c5844ce5",
   "metadata": {},
   "source": [
    "| Item/Capacity | 0  | 1  | 2  | 3  | 4  | 5  | 6  | 7  | 8  | 9  | 10 | 11 | 12 | 13 |\n",
    "|---------------|----|----|----|----|----|----|----|----|----|----|----|----|----|----|\n",
    "| Item 1        | 0  | 0  | 3  | 3  | 3  | 3  | 3  | 3  | 3  | 3  | 3  | 3  | 3  | 3  |\n",
    "| Item 2        | 0  | 0  | 3  | 4  | 4  | 7  | 7  | 7  | 7  | 7  | 7  | 7  | 7  | 7  |\n",
    "| Item 3        | 0  | 2  | 3  | 5  | 5  | 7  | 8  | 8  | 10 | 10 | 10 | 10 | 10 | 10 |\n",
    "| Item 4        | 0  | 2  | 3  | 5  | 10 | 12 | 13 | 15 | 15 | 17 | 20 | 22 | 23 | 25 |\n",
    "| Item 5        | 0  | 2  | 3  | 5  | 10 | 12 | 13 | 15 | 21 | 23 | 24 | 26 | 26 | 28 |\n",
    "| Item 6        | 0  | 2  | 3  | 5  | 10 | 12 | 15 | 15 | 21 | 23 | 26 | 26 | 29 | 29 |\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b89fae6-f547-4805-9758-79d38d795f03",
   "metadata": {},
   "source": [
    "Based on the dynamic programming table provided:\n",
    "\n",
    "The maximum total value achievable is 29, which is the maximum value obtainable for a knapsack with a capacity of 13.\n",
    "To reach this maximum value, the items you should choose are:\n",
    "Item 1: Weight 2, Value 3\n",
    "Item 4: Weight 4, Value 10\n",
    "Item 5: Weight 5, Value 11\n",
    "Item 6: Weight 2, Value 3\n",
    "These four items have a combined weight of 13 (2 + 4 + 5 + 2 = 13) and a combined value of 27 (3 + 10 + 11 + 3 = 27), consistent with the results in the dynamic programming table.\n",
    "\n",
    "Therefore, with a knapsack capacity of 13, to maximize the total value, we should select items 1, 4, 5, and 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e49a671-a125-446e-8028-cf555a674c84",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "Using ChatGPT for homework assistance involved a process where the primary goal was leveraging its comprehension and creative capabilities to deepen my understanding of the task at hand, expand my thought process, and generate similar, novel questions based on the originals. Below, I detail the specific steps involved, the challenges encountered, the solutions adopted, and the insights and reflections gained from this experience.\n",
    "\n",
    "Process:\n",
    "\n",
    "Understanding the Template Questions: I initiated the process by inputting the assignment's questions into ChatGPT. These questions often required in-depth understanding and analysis. Through interacting with ChatGPT, I sought not only a surface-level interpretation but also a deeper exploration of the underlying concepts and themes.\n",
    "Creating Similar Questions: Once ChatGPT comprehended the initial questions, I asked it to generate new ones, mirroring the core ideas of the original. This step tested whether it grasped the questions truly and could produce new problems requiring resolutions to the same central issues.\n",
    "Answering the Questions: Finally, I tackled these newly crafted questions myself, applying the knowledge gleaned from the original questions, and attempting to solve them.\n",
    "Challenges and Solutions:\n",
    "\n",
    "Contextual Understanding: At times, ChatGPT might not fully apprehend the deeper implications or complex context behind a question. When this occurred, I tried reformulating my queries or providing more background information to help the model understand better.\n",
    "Quality of Generated Questions: In some instances, the questions created by ChatGPT were overly simplistic, lacking the complexity or depth of the original problems. To address this, I provided feedback and pinpointed aspects needing improvement, guiding ChatGPT towards producing more complex and relevant questions.\n",
    "Insights and Reflections:\n",
    "\n",
    "Enhanced Conceptual Understanding: This process was remarkably beneficial in broadening my comprehension of the topics at hand. By engaging with ChatGPT, I could explore various angles and facets of a problem, enhancing my critical thinking skills.\n",
    "Creativity in Problem-Solving: Generating new questions forced me to think outside the box and apply concepts in novel ways. It was an exercise in creative thinking, as much as it was in problem-solving.\n",
    "AI's Limitations and Human Oversight: The experience underscored the importance of human oversight. AI, as advanced as ChatGPT, still had moments of misunderstanding or oversimplification. It reinforced that while AI can be a valuable tool for education, it doesn't replace human judgment and intuition.\n",
    "Ethical Considerations: Relying on AI for educational tasks brought forth ethical considerations, such as maintaining academic integrity and ensuring original thought in responses. It's crucial to use such tools responsibly, ensuring they assist in the learning process rather than just providing answers.\n",
    "In conclusion, using ChatGPT as a study aid was an enlightening experience that bolstered my understanding and problem-solving skills but also highlighted the critical need for human oversight and ethical responsibility in using AI tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841e7a57-1051-4fee-a905-11adf80533df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go",
   "language": "go",
   "name": "gophernotes"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
